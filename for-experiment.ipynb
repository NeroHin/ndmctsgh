{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-data-transformation\n",
    "\n",
    "```\n",
    "action：\n",
    "1. 將資料轉換為可以被機器學習的資料\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "start to pre-process data\n",
      "      PID     UID  leadI  leadII  leadIII  leadaVR  leadaVL  leadaVF  leadV1  \\\n",
      "0  P00001  U00001      4       7        3       -6        0        5      -4   \n",
      "1  P00001  U00001     30      56       23      -43        2       40     -43   \n",
      "2  P00001  U00001    -10      -9       -1        9       -5       -4     -31   \n",
      "3  P00001  U00001    -23     -37      -14       29       -6      -25       5   \n",
      "4  P00001  U00001    -20     -36      -17       28       -2      -26      19   \n",
      "\n",
      "   leadV2  leadV3  leadV4  leadV5  leadV6  index  label  \n",
      "0      -4      -5      -3       7       8      0      0  \n",
      "1     -66     -57     -26      31      54      1      0  \n",
      "2     -62     -73     -60     -34     -14      2      0  \n",
      "3     -11     -49     -65     -67     -70      3      0  \n",
      "4      19     -28     -50     -55     -67      4      0  \n",
      "=========================================\n",
      "start to normalize data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:55<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PID     UID     leadI    leadII   leadIII   leadaVR   leadaVL   leadaVF  \\\n",
      "0  P00001  U00001  0.296869  0.471438  0.213924 -0.411835  0.043186  0.387572   \n",
      "1  P00001  U00001  1.984000  3.529671  1.414089 -3.198680  0.187358  2.820607   \n",
      "2  P00001  U00001 -0.611585 -0.527169 -0.026109  0.717967 -0.317246 -0.238066   \n",
      "3  P00001  U00001 -1.455150 -2.274731 -0.806216  2.224370 -0.389332 -1.697887   \n",
      "4  P00001  U00001 -1.260482 -2.212318 -0.986240  2.149050 -0.100987 -1.767402   \n",
      "\n",
      "     leadV1    leadV2    leadV3    leadV4    leadV5    leadV6  index  label  \n",
      "0 -0.093803 -0.078097 -0.103556 -0.050878  0.151533  0.163429      0      0  \n",
      "1 -1.155804 -1.484437 -1.294750 -0.519747  0.638118  1.048169      1      0  \n",
      "2 -0.829034 -1.393705 -1.661272 -1.212858 -0.679717 -0.259707      2      0  \n",
      "3  0.151275 -0.236877 -1.111490 -1.314786 -1.348771 -1.336782      3      0  \n",
      "4  0.532506  0.443610 -0.630430 -1.009001 -1.105478 -1.279081      4      0  \n",
      "=========================================\n",
      "start to split data\n",
      "train id list length: 1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3071/3071 [00:00<00:00, 68597.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test id list length: 614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3071/3071 [00:00<00:00, 61177.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test id list length: 614\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5881000/5881000 [03:22<00:00, 29054.21it/s]\n",
      "100%|██████████| 1984000/1984000 [01:03<00:00, 31201.02it/s]\n",
      "100%|██████████| 1934000/1934000 [01:02<00:00, 30863.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_uni.shape -- (5881000, 100, 12)\n",
      "y_train_uni.shape -- (5881000, 100)\n",
      "x_val_uni.shape -- (1984000, 100, 12)\n",
      "y_val_uni.shape -- (1984000, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 17:30:55.440793: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-25 17:30:55.477574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-25 17:30:55.504555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.62GHz coreCount: 72 deviceMemorySize: 22.17GiB deviceMemoryBandwidth: 581.23GiB/s\n",
      "2022-08-25 17:30:55.506296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.62GHz coreCount: 72 deviceMemorySize: 22.17GiB deviceMemoryBandwidth: 581.23GiB/s\n",
      "2022-08-25 17:30:55.506456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-25 17:30:55.512297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-25 17:30:55.512656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-25 17:30:55.524446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-25 17:30:55.526536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-25 17:30:55.531489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-25 17:30:55.533938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-25 17:30:55.543952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-25 17:30:55.548084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-08-25 17:30:55.605848: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-25 17:30:55.628086: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-25 17:30:55.835324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.62GHz coreCount: 72 deviceMemorySize: 22.17GiB deviceMemoryBandwidth: 581.23GiB/s\n",
      "2022-08-25 17:30:55.836201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.62GHz coreCount: 72 deviceMemorySize: 22.17GiB deviceMemoryBandwidth: 581.23GiB/s\n",
      "2022-08-25 17:30:55.836237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-25 17:30:55.836263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-25 17:30:55.836273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-25 17:30:55.836284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-25 17:30:55.836295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-25 17:30:55.836306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-25 17:30:55.836316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-25 17:30:55.836327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-25 17:30:55.839213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-08-25 17:30:55.839677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-25 17:30:56.978641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-25 17:30:56.978677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-08-25 17:30:56.978682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2022-08-25 17:30:56.978685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2022-08-25 17:30:56.981922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 16684 MB memory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n",
      "2022-08-25 17:30:56.985606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 21045 MB memory) -> physical GPU (device: 1, name: Quadro RTX 6000, pci bus id: 0000:d8:00.0, compute capability: 7.5)\n",
      "2022-08-25 17:30:57.000735: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 56457600000 exceeds 10% of free system memory.\n",
      "2022-08-25 17:31:51.141289: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19046400000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# import cudf as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc, roc_curve, precision_recall_curve, average_precision_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "df_path = 'dataset/train_with_ecg.csv'\n",
    "\n",
    "\n",
    "def pre_process(df):\n",
    "    # remove older label\n",
    "    df.drop(columns=['label'], inplace=True)\n",
    "    \n",
    "    # create new label\n",
    "    df['label'] = df['EF'].apply(lambda x: 1 if x <= 35 else 0)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def normalize(df):\n",
    "    # remove label, PID, UID, index\n",
    "    cols = df.drop(columns=['label', 'PID','UID', 'index']).columns\n",
    "    \n",
    "    # normalize data\n",
    "    for item in tqdm(cols):\n",
    "        mean_tmp = np.mean(np.array(df[item]))\n",
    "        std_tmp = np.std(np.array(df[item]))\n",
    "        if(std_tmp):\n",
    "            df[item] = df[item].apply(lambda x: (x - mean_tmp) / std_tmp)\n",
    "            \n",
    "    return df\n",
    "            \n",
    "\n",
    "def univariate_data(df, history_size, target_size):\n",
    "    target = df.values[:,-1]\n",
    "    df = df.drop(['label'],axis=1).values\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = history_size\n",
    "    end_index = len(df)\n",
    "    \n",
    "    # 多特徵\n",
    "    for i in tqdm(range(start_index, end_index)):\n",
    "\n",
    "        indices = range(i-history_size, i,10) # step表示滑动步长\n",
    "        data.append(df[indices])\n",
    "        labels.append(target[indices])\n",
    "        \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "def buildManyToOneModel(shape, layer=1):\n",
    "\n",
    "    input_nodes = shape[1] * shape[2]\n",
    "    output_nodes = 1\n",
    "    hidden_nodes = int(round(2/3 * (input_nodes + output_nodes)))\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    if layer == 1:\n",
    "        model.add(GRU(hidden_nodes, input_length=shape[1], input_dim=shape[2], kernel_initializer='normal'))\n",
    "        model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    PRC = tf.keras.metrics.AUC(curve='PR')\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=[tf.keras.metrics.binary_accuracy,tf.keras.metrics.Recall(), PRC , tf.keras.metrics.AUC(curve='ROC')],run_eagerly=True)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# mian function\n",
    "\n",
    "df = pd.read_csv(df_path).sort_values(by=['PID', 'UID', 'index'])\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"start to pre-process data\")\n",
    "pre_process(df=df)\n",
    "# drop ef column\n",
    "df = df.drop(columns=['EF'])\n",
    "print(df.head())\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"start to normalize data\")\n",
    "normalize(df=df)\n",
    "print(df.head())\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"start to split data\")\n",
    "    # list of pid \n",
    "pid_list = df.PID.unique().tolist()\n",
    "\n",
    "# random shuffle pid list, select no repeat 0.6 from train, 0.2 from test, 0.2 from validation\n",
    "# ref: https://stackoverflow.com/questions/4211209/remove-all-the-elements-that-occur-in-one-list-from-another\n",
    "\n",
    "train_id = np.random.choice(pid_list, int(len(pid_list) * 0.6), replace=False).tolist()\n",
    "print(f\"train id list length: {len(train_id)}\")\n",
    "\n",
    "test_id  = np.random.choice([x for x in tqdm(pid_list) if x not in train_id], int(len(pid_list) * 0.2), replace=False).tolist()\n",
    "print(f\"test id list length: {len(test_id)}\")\n",
    "\n",
    "# sum of train and test id array\n",
    "train_test_id_list = train_id + test_id\n",
    "\n",
    "vali_id = np.random.choice([x for x in tqdm(pid_list) if x not in train_test_id_list], int(len(pid_list) * 0.2), replace=False).tolist()\n",
    "print(f\"test id list length: {len(test_id)}\")\n",
    "\n",
    "\n",
    "train_df = df[df['PID'].isin(train_id)].reset_index(drop=True).drop(['PID'],axis=1).sort_values(by=['UID', 'index']).drop(columns=['UID', 'index'])\n",
    "test_df = df[df['PID'].isin(test_id)].reset_index(drop=True).drop(['PID'],axis=1).sort_values(by=['UID', 'index']).drop(columns=['UID', 'index'])\n",
    "validation_df = df[df['PID'].isin(vali_id)].reset_index(drop=True).drop(['PID'],axis=1).sort_values(by=['UID', 'index']).drop(columns=['UID', 'index'])\n",
    "\n",
    "\n",
    "print(\"=========================================\")\n",
    "\n",
    "x_train_single, y_train_single = univariate_data(train_df,1000,0)\n",
    "x_val_single, y_val_single = univariate_data(validation_df,1000,0)\n",
    "x_test,y_test = univariate_data(test_df,1000,0)\n",
    "\n",
    "print(f'x_train_uni.shape -- {x_train_single.shape}')\n",
    "print(f'y_train_uni.shape -- {y_train_single.shape}')\n",
    "print(f'x_val_uni.shape -- {x_val_single.shape}')\n",
    "print(f'y_val_uni.shape -- {y_val_single.shape}')\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 150\n",
    "\n",
    "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\n",
    "train_data_single = train_data_single.cache().batch(BATCH_SIZE).shuffle(BUFFER_SIZE)#.repeat().shuffle(BUFFER_SIZE)\n",
    "\n",
    "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\n",
    "val_data_single = val_data_single.batch(BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57630/2456565489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m callbacks_list = [\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m ]\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "]\n",
    "\n",
    "\n",
    "model = buildManyToOneModel(shape=x_train_single.shape)\n",
    "\n",
    "\n",
    "history = model.fit(train_data_single, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_data=val_data_single, callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "Y_testPred = model.predict(X_test_shuffled)\n",
    "\n",
    "\n",
    "# AUC-ROC\n",
    "fpr, tpr, threshold = roc_curve(y_true=y_test, y_score=Y_testPred)\n",
    "# np.save(\n",
    "#     NNModel_folderpath + f'NN_Classifier_{classifier_name}_{layer}hiddenlayer-fprtpr-features_{feature_set}-target_{classify_label}-window_{input_window * 2}mins-sampling_{sampling_name}-round_{round_id}-{timestamp}.npy',\n",
    "#     np.array([fpr, tpr]))\n",
    "auc_score = auc(fpr, tpr)\n",
    "# AUC-ROC best threshold\n",
    "best_thre, best_tpr, best_fpr = opt_threshold(fpr, tpr, threshold, auc_score)\n",
    "# AUC-PRC & Average precision socre\n",
    "prc_precision, prc_recall, prc_threstholds = precision_recall_curve(y_true=y_test, probas_pred=Y_testPred)\n",
    "ap_score = average_precision_score(y_true=y_test, y_score=Y_testPred)\n",
    "\n",
    "Y_testPred = [1 if y >= best_thre else 0 for y in Y_testPred]\n",
    "cm = confusion_matrix(y_pred=Y_testPred, y_true=y_test)\n",
    "\n",
    "# metrics\n",
    "f1 = f1_score(y_pred=Y_testPred, y_true=y_test)\n",
    "sensitivity = cm[1][1] / (cm[1][1] + cm[1][0])  # TP/(TP+FN)\n",
    "specificity = cm[0][0] / (cm[0][0] + cm[0][1])  # TN/(TN+FP)\n",
    "precision_1 = cm[1][1] / (cm[1][1] + cm[0][1])  # TP/(TP+FP)\n",
    "recall_1 = cm[1][1] / (cm[1][1] + cm[1][0])  # TP/(TP+FN)\n",
    "accuracy = (cm[1][1] + cm[0][0]) / (cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])  # (TP+TN)/(TP+FP+FN+TN)\n",
    "# model.save(NNModel_folderpath + f'NN_Classifier_{classifier_name}_{layer}hiddenlayer-features_{feature_set}-target_{classify_label}-window_{input_window * 2}mins-sampling_{sampling_name}-round_{round_id}-f1_{f1:.3f}-{timestamp}.h5')\n",
    "\n",
    "# delete model to release RAM\n",
    "del model\n",
    "gc.collect()\n",
    "\n",
    "df_res = pd.DataFrame([[auc_score, best_thre, f1, sensitivity, specificity,\n",
    "                        precision_1, recall_1, accuracy, ap_score,cm[0][0], cm[0][1], cm[1][0], cm[1][1]]],\n",
    "                        columns=['AUC', 'best_threshold', 'f1_score', 'sensitivity', 'specificity',\n",
    "                                'precision_label1', 'recall_label1', 'accuracy', 'ap_score','TN', 'FP', 'FN', 'TP'])\n",
    "print(df_res.T)\n",
    "print(f'Confusion Matrix: \\n{cm}')\n",
    "print(f'Classification Report: \\n{classification_report(y_true=y_test, y_pred=Y_testPred)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29618/2720607242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(train_data_single, epochs=EPOCHS, batch_size=BATCH_SIZE,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     validation_data=val_data_single, callbacks=callbacks_list, verbose=1)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_testPred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_shuffled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ec457515959363901d7ccb61b0e0e67fe0f5d7e34a074d892d26ce3aecbc0ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
